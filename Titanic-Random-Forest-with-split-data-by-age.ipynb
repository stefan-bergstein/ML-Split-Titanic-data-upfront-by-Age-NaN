{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "ed598c10-44fb-49fa-95ab-01fc405725e5",
        "_uuid": "70e87b309f2ed2ad2314942320b4047cd79d9bac"
      },
      "cell_type": "markdown",
      "source": "# Split Titanic data upfront - A simple attempt for separate predictions\n\n\n---\n\nThe Age-feature in the Titanic data is not defined for many passengers. Several good Kaggle notebooks do feature engineering to come up with replacements of the missing age data (e.g. [Titanic Data Science Solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook)).\n\nI was wondering if it would be possible to just .... \n1. ** separate the training and test data ** into two buckets (Age defined vs. Age NaN), \n2. do **predictions separately**, and \n3. finally, ** concatenate the results**.\n\n\nAdditionally, the notebook includes basic hyperparameter tuning for RandomForest and AdaBoost.\n\n## Overview:\n\n- Import modules, read data and display some data\n- Prepare subset of training and test data without any NaN in Age\n- Predict 'Survived' for passengers data with Age\n - Grid search and fit with Random Forest Classifier\n - Grid search and fit with AdaBoost Classifier\n - Predict based on better algorithm and score\n- Predict 'Survived' with Random Forest Classifier for passengers data without Age\n- Concatenate predictions\n- Summary\n\n"
    },
    {
      "metadata": {
        "_cell_guid": "4295e855-c290-4fbf-9bb4-4d93afc996a5",
        "_uuid": "4bc35a5804458f6210e104868cf86171b5bf9f54"
      },
      "cell_type": "markdown",
      "source": "### Import modules, read data and display some data\n\n\nAs usual, import modules, read data and display some data"
    },
    {
      "metadata": {
        "_cell_guid": "c1e06520-94ff-46a4-ac26-564c6fe3d4b4",
        "_uuid": "34bd97d22195804c4397e2bf2e4e07711a72f29f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# data processing\nimport numpy as np\nimport pandas as pd \n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\n\n\n\n# some configuratin flags and variables\nverbose = 1 # Use in classifier\nquick_run = True # if set to True, use only few variabales during hyperparameter tuning\nn_jobs = -1\n\n# Input files\nfile_train='../input/train.csv'\nfile_test='../input/test.csv'\n\n# define random seed for reproducibility\nseed = 69\nnp.random.seed(seed)\n\n# read training and test data\ntrain_df = pd.read_csv(file_train,index_col='PassengerId')\ntest_df = pd.read_csv(file_test,index_col='PassengerId')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1da41e1b-e5ee-4ba5-af19-e417dcc52062",
        "_uuid": "874d595eba2e6d7bd62343bada9b1fb2858820fc"
      },
      "cell_type": "markdown",
      "source": "#### Brief data preview:"
    },
    {
      "metadata": {
        "_cell_guid": "72e4a340-0620-471b-8285-c2f2725cadff",
        "_uuid": "325389cdb7e26469f0a6c3b38068b24e6c0ebe6a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Show the columns\ntrain_df.columns.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b94516bd-edf3-43ad-9310-5a139e55385b",
        "_uuid": "d80e7b9d3da054624d6b4c2403ed7f672c32de18",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Show the shape\ntrain_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0ab7460e-1c7c-495a-bd65-851c7929b3ee",
        "_uuid": "0fb037a155c5f588e95cd157d9d744e3f061575e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# preview the training data\ntrain_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "03673027-92b2-4927-be14-e3941413ac43",
        "_uuid": "fdbe1967443485bf3059b5e20111e92675174254",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1bb49787-cf92-4e58-8dd9-3ae5fdabcabb",
        "_uuid": "cb3347790c40767ec7de9905522344d8cfd981a2",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Show that there is NaN data (Age,Fare Embarked), that needs to be handled.\ntrain_df.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "766af68f-efaa-410c-8b19-775f8c528c7a",
        "_uuid": "fb1af8c7fb6ff23f6d54390dac6d1f70c3002962"
      },
      "cell_type": "markdown",
      "source": "#### A function for simple data cleansing without the Age features\n- Drop unwanted features ['Name', 'Ticket', 'Cabin']\n- Fill missing data: Fare with the mean, Embarked with most frequent value\n- Convert categorical features into numeric\n- Convert Embarked to one-hot\n- Note, missing data of the Age features is not filled."
    },
    {
      "metadata": {
        "_cell_guid": "5c1b4c78-087f-43b5-9edb-298a7e622236",
        "_uuid": "92d6dfd08ac18a5e24b366181c520dd2e72700b9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def prep_data(df):\n    # Drop unwanted features\n    df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n    \n    # Fill missing data:  Fare with the mean, Embarked with most frequent value\n    df[['Fare']] = df[['Fare']].fillna(value=df[['Fare']].mean())\n    df[['Embarked']] = df[['Embarked']].fillna(value=df['Embarked'].value_counts().idxmax())\n    \n    # Convert categorical  features into numeric\n    df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n      \n    # Convert Embarked to one-hot\n    enbarked_one_hot = pd.get_dummies(df['Embarked'], prefix='Embarked')\n    df = df.drop('Embarked', axis=1)\n    df = df.join(enbarked_one_hot)\n\n    return df\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "385d1c91-9f0b-425e-bebc-40de132e5f88",
        "_uuid": "8d336896a29d23ff0b738f31d442212869c8e1cb"
      },
      "cell_type": "markdown",
      "source": "### Prepare subset of training and test data without any NaN in Age\n\nPrepare training data without any NaN in Age (**train_df_age_no_nan**). \nShow that there isn't any null data"
    },
    {
      "metadata": {
        "_cell_guid": "f4222a58-2d07-4d32-9866-77e483728bdd",
        "_uuid": "ed6a920a1a8a544181cca91669533481ed091182",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df = prep_data(train_df)\ntrain_df_age_no_nan = train_df[train_df['Age'].notnull()]\nprint(\"Training data without any NaN in Age:\\n\", train_df_age_no_nan.isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b977c868-29c7-4fbf-bcaa-0d53257635ae",
        "_uuid": "5ed459fd452557ae3b418651460bddb1214de4b3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df_age_no_nan.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "faa863ca-4db3-4983-99d2-c89ddf9460c0",
        "_uuid": "52f4df449f481c07f235925caab1ce0a1d321942"
      },
      "cell_type": "markdown",
      "source": "**Visualise feature correlation with a heatmap**\n\nAs expected, only the Gender is correlated to 'Survived'"
    },
    {
      "metadata": {
        "_cell_guid": "c4b4f225-1aeb-40ff-8666-3ea5a3c3d066",
        "_uuid": "f0d4464247e1c1fe8dcad278852ea715918a7e41",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cmap = plt.cm.RdBu\ncorr = train_df_age_no_nan.corr()\nplt.figure(figsize=(12,10))\nplt.title('Pearson Features Correlation of training data without NaN in Age', size=15)\nsns.heatmap(corr, cmap=cmap,  annot=True, linewidths=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6aaccc1f-679f-45d3-9720-b18d4a3d7848",
        "_uuid": "16a28973997846e3b44bfa0d860ca299a18a4321"
      },
      "cell_type": "markdown",
      "source": "** Show pairplots to visualize the distribution of data across features **\n\nFurther drill down could be helpfull. There are several Kaggel notebooks showing in-depth visualisations, data exploration and wrangling on the Titanic data:\n- [In-Depth Visualisations - Simple Methods](https://www.kaggle.com/jkokatjuhha/in-depth-visualisations-simple-methods)\n- [Titanic Data Exploration Starter](https://www.kaggle.com/neviadomski/titanic-data-exploration-starter)\n- [Titanic Data Science Solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook)\n"
    },
    {
      "metadata": {
        "_cell_guid": "99fcf853-0052-42b9-913e-869cc0a24dbb",
        "_uuid": "392c285d0216e446641a4ae013321cffae1c1982",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "g = sns.pairplot(train_df_age_no_nan, hue='Survived', palette = 'seismic',size=1.5,diag_kind='kde',diag_kws=dict(shade=True),plot_kws=dict(s=10))\ng.set(xticklabels=[])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d7917bfd-a46a-4c10-a47c-97183d2d7c14",
        "_uuid": "0630e7d2d654e7207d1229e0f684991af4ad8079"
      },
      "cell_type": "markdown",
      "source": "Prepare test data without any NaN in Age (**test_df_age_no_nan**). "
    },
    {
      "metadata": {
        "_cell_guid": "c373b57b-47ef-4030-9502-3809ff6a32f9",
        "_uuid": "1de0f838a446ca72a90f17a8663b3e79f3f0ecb5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_df = prep_data(test_df)\ntest_df_age_no_nan = test_df[test_df['Age'].notnull()]\nprint(\"Test data without any NaN in Age:\\n\", test_df_age_no_nan.isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "692662e5-3e7f-4e44-b046-4aaa7ffd45fa",
        "_uuid": "b06b603a62e555fcab4825abd47debabe34bccf8",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_df_age_no_nan.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ed428940-261a-41f5-a7b4-c6ed2c16300a",
        "_uuid": "8adc554c625c9a47070ec08cc102a26b7c972386"
      },
      "cell_type": "markdown",
      "source": "### Predict 'Survived' for passengers data with Age\n\nSplit training data into input X and output Y"
    },
    {
      "metadata": {
        "_cell_guid": "edf52f20-3fed-4ce7-9a70-6c59f061ed6f",
        "_uuid": "af715dcfc105d1fbd3526ba3ee1802abbb8f8b79",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# X contains all columns except 'Survived'  \nX = train_df_age_no_nan.drop(['Survived'], axis=1).values.astype(float)\n\n# Y is just the 'Survived' column\nY = train_df_age_no_nan['Survived'].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a6649bf1-3928-4a06-b12d-2da10d03b6ae",
        "_uuid": "8ba15334a82c79e58711a37ac48435ff19078318",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "#### Grid search and fit with Random Forest Classifier"
    },
    {
      "metadata": {
        "_cell_guid": "eb071a81-8459-4584-a210-d0b3c4a4f8bf",
        "_uuid": "9847a1b0ebb72914d0c7b7d6741c2b8fa4855e9d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "kfold = KFold(n_splits=10, random_state=seed)\n\nif quick_run:\n    rf_parameters = {\"max_depth\": [4,8]\n                ,\"min_samples_split\" :[2,6]\n                ,\"n_estimators\" : [100]\n                ,\"min_samples_leaf\": [1,2]\n                ,\"max_features\": [6,\"sqrt\"]\n                ,\"criterion\": ['gini']}       \nelse:\n    rf_parameters = {\"max_depth\": [2,4,6,8,12]\n                ,\"min_samples_split\" :[2,3,5,8]\n                ,\"n_estimators\" : [50, 100,200]\n                ,\"min_samples_leaf\": [2,3,5]\n                ,\"max_features\": [4,6,\"sqrt\"]\n                ,\"criterion\": ['gini','entropy']}\n\nprint('** GridSearchCV RF ...') \nrf_clf = RandomForestClassifier()\nrf_grid = GridSearchCV(rf_clf,rf_parameters, n_jobs = n_jobs, verbose = verbose, cv = 10)\nrf_grid.fit(X,Y)\n\nprint('Best score RF: {}'.format(rf_grid.best_score_))\nprint('Best parameters RF: {}'.format(rf_grid.best_params_))\n\nrf_clf = RandomForestClassifier(**rf_grid.best_params_)\nrf_clf.fit(X,Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fc970ed5-9a50-4f46-85e8-5bf93f2fd22d",
        "_uuid": "43a83af82846ff5ec163fd6c65269b70ddb2dd2f"
      },
      "cell_type": "markdown",
      "source": "#### Grid search and fit with AdaBoost Classifier"
    },
    {
      "metadata": {
        "_cell_guid": "7925bcaf-dc0d-444b-aa0e-207c184936db",
        "_uuid": "86be81ad997c55b51abfda41762278f94749949d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if quick_run:\n    ab_parameters = {'n_estimators':[50,100,200,300],\n                  'learning_rate':[0.1,0.5,1.0,2.0]}\nelse:\n    ab_parameters = {'n_estimators':[50,100],\n                  'learning_rate':[0.5,1.0]}\n    \nprint('** GridSearchCV AB ...') \nab_clf = AdaBoostClassifier()\nab_grid = GridSearchCV(ab_clf,ab_parameters, n_jobs = n_jobs, verbose = verbose, cv = 10)\nab_grid.fit(X,Y)\n\nprint('Best score AB: {}'.format(ab_grid.best_score_))\nprint('Best parameters AB: {}'.format(ab_grid.best_params_))\n\nab_clf = AdaBoostClassifier(**ab_grid.best_params_)\nab_clf.fit(X,Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1b57a520-8637-480d-9388-9bcfbba5506f",
        "_uuid": "6fad616311579613bcf0fdf6284fb58ba9458cbe"
      },
      "cell_type": "markdown",
      "source": "#### Predict based on better algorithm and score"
    },
    {
      "metadata": {
        "_cell_guid": "0de287ef-3cb8-44d2-97c7-75c2d732d925",
        "_uuid": "03f2517996ab00d3139c3b1bbbfa7ba6deff1a25",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Create X_test\nX_test = test_df_age_no_nan.values.astype(float)\n\n\n# Predict 'Survived' for Age no NaN\nif ( rf_grid.best_score_ > ab_grid.best_score_ ) :\n    print('** Predict Survived for data with age using RF {}'.format(rf_grid.best_params_))\n    prediction_age_no_nan = rf_clf.predict(X_test)\nelse:\n    print('** Predict Survived for data with age using AB {}'.format(ab_grid.best_params_))\n    prediction_age_no_nan = ab_clf.predict(X_test)\n\n\nsubm_no_nan = pd.DataFrame({\n    'PassengerId': test_df_age_no_nan.index,\n    'Survived': prediction_age_no_nan,\n})\n    \ntest_df_age_nan = test_df[test_df['Age'].isnull()]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "913d521f-efa0-4249-be52-17ac04e0ce0a",
        "_uuid": "8dc1378568fc5fcc4f89b593d036955107d228fe"
      },
      "cell_type": "markdown",
      "source": "### Predict 'Survived' for passengers data without Age\n\n#### Grid search,  fit and predict with Random Forest Classifier"
    },
    {
      "metadata": {
        "_cell_guid": "7ba930af-f423-45e3-9c0f-654a4f66d704",
        "_uuid": "c3732325e4a6d09c33a0fa78e68c57451405efbc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Split training data into input X and output Y\n\ntrain_df_age_nan = train_df[train_df['Age'].isnull()]\n\n# X contains all columns except Age and 'Survived'  \nX = train_df.drop(['Age','Survived'], axis=1).values.astype(float)\n\n# Y is just the 'Survived' column\nY = train_df['Survived'].values\n\n\nkfold = KFold(n_splits=10, random_state=seed)\n\nprint('** GridSearchCV (no Age) RF ...') \nrf_clf = RandomForestClassifier()\nrf_grid = GridSearchCV(rf_clf,rf_parameters, n_jobs = n_jobs, verbose = verbose, cv = 10)\nrf_grid.fit(X,Y)\n\nprint('Best score (no Age) RF: {}'.format(rf_grid.best_score_))\nprint('Best parameters (no Age) RF: {}'.format(rf_grid.best_params_))\n\n\nrf_clf = RandomForestClassifier(**rf_grid.best_params_)\nrf_clf.fit(X,Y)\n\n# Predict test data with Age == NaN\nX_test_age_nan = test_df_age_nan.drop(['Age'], axis=1).values.astype(float)\n\n# Predict 'Survived'\nprediction_age_nan = rf_grid.predict(X_test_age_nan)   \n\nsubm_nan = pd.DataFrame({\n    'PassengerId': test_df_age_nan.index,\n    'Survived': prediction_age_nan\n})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4a72ffa7-65f9-487c-ad28-a9da3868b758",
        "_uuid": "27889ba7e615e8e713ffc98f327b5afc146a1276"
      },
      "cell_type": "markdown",
      "source": "### Concatenate predictions"
    },
    {
      "metadata": {
        "_cell_guid": "ce13586c-045e-470b-8088-d2905731c926",
        "_uuid": "0293047610240aae4db5b37eacf0b58041a18cc0",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# stack the DataFrames on top of each other\nsubmission = pd.concat([subm_no_nan, subm_nan], axis=0)\n\nsubmission.sort_values('PassengerId', inplace=True)    \nsubmission.to_csv('submission-splitt-input.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3ea84fe7-8de9-4959-ae56-670e9ad68771",
        "_uuid": "460c43128592a17f328517b21efe2b63b24af893"
      },
      "cell_type": "markdown",
      "source": "## Summary\nThe score is not really great (~0.76) but comparable to many other simple approaches. My experiment illustrated that splitting the test and training data upfront due to data quality issues could be a reasonable approach.\n\n\nYour feedback and suggestions are very welcome."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "anaconda-cloud": {},
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.3",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}